import streamlit as st
from streamlit_chat import message
from utils import chat, imagegen, asr
import pandas as pd
from markdown2 import markdown as markdown2
from markdown import markdown
import time
# from streamlit_extras.colored_header import colored_header
from streamlit_extras.buy_me_a_coffee import button

WIDE_LAYOUT_THRESHOLD = 400

# è®¾ç½®é¡µé¢æ ‡é¢˜
if 'layout' not in st.session_state:
    st.session_state.layout = 'centered'
st.set_page_config(page_title="æ˜Ÿå°˜å°åŠ©æ‰‹", page_icon=":star:", 
                   layout=st.session_state.layout, 
                   initial_sidebar_state="collapsed", menu_items={
             'Get Help': 'https://stardust.ai',
            #  'Report a bug': "https://www.extremelycoolapp.com/bug",
             'About': "# æ˜Ÿå°˜å°åŠ©æ‰‹. \n *ä»…é™å‘˜å·¥ä½¿ç”¨ï¼Œè¯·å‹¿å¤–ä¼ !*"
    })
st.title("ğŸªæ˜Ÿå°˜å°åŠ©æ‰‹")

# åå­—
with open('names.txt', 'r') as f:
    names = [n.strip() for n in f.readlines()]
name_pl = st.empty()
if 'my_name' not in st.session_state:
    if 'name' in st.session_state and st.session_state.name != '':
        st.session_state.my_name = st.session_state.name
    else:
        st.warning('æœ¬ç³»ç»Ÿéœ€è¦æ¶ˆè€—è®¡ç®—èµ„æºï¼Œç‰¹åˆ«æ˜¯å›¾ç‰‡å’Œè¯­éŸ³åŠŸèƒ½ï¼›è¯·é€‚åº¦ä½“éªŒAIçš„èƒ½åŠ›ï¼Œå°½é‡ç”¨åœ¨å·¥ä½œç›¸å…³å†…å®¹ä¸ŠğŸ˜Š')
        st.session_state.name = name_pl.text_input('è¯·è¾“å…¥ä½ çš„åå­—', key='my_name', help='ä»…é™å‘˜å·¥ä½¿ç”¨ï¼Œè¯·å‹¿å¤–ä¼ ï¼')
else:
    st.session_state.name = st.session_state.my_name
if st.session_state.name == '':
    st.stop()
elif st.session_state.name not in names:
    st.warning('è¯·è¾“å…¥æ­£ç¡®çš„åå­—ä»¥ä½¿ç”¨æœ¬ç³»ç»Ÿ')
    st.stop()
else:
    name_pl.empty()
    

# å®šä¹‰ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºä¿å­˜å¯¹è¯å†…å®¹ã€‚roleï¼šsystemï¼Œuserï¼Œassistant
if "conversation" not in st.session_state:
    st.session_state.conversation = chat.init_prompt.copy()
    

## UI
# å¯¹æ–‡æœ¬è¾“å…¥è¿›è¡Œåº”ç­”
def gen_response():
    task = st.session_state.task
    if task in ['å¯¹è¯', 'ä½œå›¾']:
        user_input = st.session_state.input_text
        if user_input == '':
            return
        st.session_state.input_text = ""
    elif task == 'è¯­éŸ³è¯†åˆ«':
        audio_file = st.session_state.audio
        if audio_file is None:
            return
        user_input = audio_file.name
        
    print(f'{st.session_state.name}({task}): {user_input}')
    st.session_state.conversation.append({"role": "user", "content": user_input})
    if task == 'å¯¹è¯':
        # with st.spinner('æ­£åœ¨æ€è€ƒ'):
            # response = bot_response["content"]
            # print(f'æ˜Ÿå°˜å°åŠ©æ‰‹: {response}')
            # print('-'*50)
        queue = chat.chat_stream(st.session_state.conversation)
        bot_response = {'role': 'assistant', 
                        'content': '', 
                        'queue': queue, 
                        'active': True,
                        'start': time.time()
                        }
        response = ''
        st.session_state.conversation.append(bot_response)
    elif task == 'ä½œå›¾':
        with st.spinner('æ­£åœ¨ç»˜åˆ¶'):
            urls = imagegen.gen_image(user_input)
            response = urls
            st.session_state.conversation.append({
                'role': 'imagen',
                'content': urls 
            })
            print(f'Imagen: {response}')
            print('-'*50)
    elif task == 'è¯­éŸ³è¯†åˆ«':
        with st.spinner('æ­£åœ¨è¯†åˆ«'):
            response = asr.transcript(audio_file)
            st.session_state.conversation.append({
                'role': 'audio',
                'content': audio_file
            })
            st.session_state.conversation.append({
                'role': 'assistant',
                'content': response 
            })
            print(f'Whisper: {response}')
            print('-'*50)
    else:
        raise NotImplementedError(task)
    # log
    with open(f'chats/{st.session_state.name}.txt', 'a') as f:
        f.write(f'{st.session_state.name}: {user_input}\n')
        f.write(f'æ˜Ÿå°˜å°åŠ©æ‰‹({task}): {response}\n')
        f.write('-'*50 + '\n')


# æ˜¾ç¤ºå¯¹è¯å†…å®¹
def finish_reply(chat):
    chat.pop('active')
    chat.pop('queue')
    chat.pop('start')
    
md_formated = ""
for i, c in enumerate(st.session_state.conversation):
    if c['role'] == "system":
        continue
    elif c['role'] == "user":
        message(c['content'], is_user=True, key=str(i),
                avatar_style='initials', seed=st.session_state.name[-2:])
    elif c['role'] == "assistant":
        if c.get('active'):
            queue = c['queue']
            # è¶…æ—¶
            if time.time() - c['start'] > 30:
                finish_reply(c)
                queue.close()
                c['content'] += '\næŠ±æ­‰å‡ºäº†ç‚¹é—®é¢˜ï¼Œè¯·é‡è¯•...'
            # è·å–æ•°æ®
            text = ''
            while queue.qsize():
                content = queue.get()
                if content == chat.finish_token:
                    finish_reply(c)
                    queue.close()
                else:
                    text += content
                    c['start'] = time.time()
            # æ¸²æŸ“
            c['content'] += text
            message(c['content'], key=str(i), avatar_style='jdenticon')
            time.sleep(0.2)
            st.experimental_rerun()
        else:
            message(c['content'], key=str(i), avatar_style='jdenticon')

    elif c['role'] == 'imagen':
        n = len(c['content'])
        cols = st.columns(n)
        for i, col, url in zip(range(1, n+1), cols, c['content']):
            with col:
                st.image(url, use_column_width=True, caption=f'å›¾{i+1}')
    elif c['role'] == 'audio':
        c1, c2 = st.columns([0.6,0.4])
        with c2:
            st.audio(c['content'])
    else:
        raise Exception(c)

    # page layout
    if st.session_state.layout != 'wide' and len(c['content']) > WIDE_LAYOUT_THRESHOLD:
        st.session_state.layout = 'wide'
        st.experimental_rerun()

# æ·»åŠ æ–‡æœ¬è¾“å…¥æ¡†
c1, c2 = st.columns([0.15,0.85])
with c1:
    task = st.selectbox('é€‰æ‹©åŠŸèƒ½', ['å¯¹è¯', 'ä½œå›¾', 'è¯­éŸ³è¯†åˆ«'], key='task', label_visibility='collapsed')
with c2:
    if task in ['å¯¹è¯', 'ä½œå›¾']:
        user_input = st.text_input(label="è¾“å…¥ä½ çš„é—®é¢˜ï¼š", placeholder='è¾“å…¥ä½ çš„é—®é¢˜ï¼Œç„¶åæŒ‰å›è½¦æäº¤ã€‚',
                            help='è¾“å…¥ä½ çš„é—®é¢˜ï¼Œç„¶åæŒ‰å›è½¦æäº¤ã€‚', 
                            max_chars=500,
                            key='input_text',
                            label_visibility='collapsed',
                            on_change=gen_response)
    elif task == 'è¯­éŸ³è¯†åˆ«':
        audio_file = st.file_uploader('ä¸Šä¼ è¯­éŸ³æ–‡ä»¶', type=asr.accepted_types, key='audio', label_visibility='collapsed', on_change=gen_response)




## åŠŸèƒ½åŒº
c1, c2, c3 = st.columns([0.1, 0.1, 0.8])
# æ¸…ç©ºå¯¹è¯
with c1:
    if st.button('ğŸ§¹', key='clear', help='æ¸…ç©ºå¯¹è¯'):
        st.session_state.conversation = chat.init_prompt.copy()
        # st.session_state.input_text = ""
        st.session_state.audio = None
        # st.session_state.task = 'å¯¹è¯'
        st.session_state.layout = 'centered'
        st.experimental_rerun()
with c2:
    # å¯¼å‡ºå¯¹è¯å†…å®¹
    def convert_history(conversation):
        history = pd.DataFrame(conversation).query('role not in ["system", "audio"]')
        return history.to_csv().encode('utf-8')
    if st.download_button(label='ğŸ“¤', help='å¯¼å‡ºå¯¹è¯',
                        data=convert_history(st.session_state.conversation), 
                        file_name=f'history.csv', 
                        mime='text/csv'):
        st.success('å¯¼å‡ºæˆåŠŸï¼')
        
from streamlit_extras.add_vertical_space import add_vertical_space
add_vertical_space(20)
# buy me a coffee
button(username="derekz", floating=False, width=221)