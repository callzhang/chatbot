import streamlit as st
from streamlit_chat import message
from utils import chat, imagegen, asr
import pandas as pd
import time
# from streamlit_extras.colored_header import colored_header
from streamlit_extras.buy_me_a_coffee import button

WIDE_LAYOUT_THRESHOLD = 400

# åˆå§‹åŒ–
st.session_state.guest = True
if 'layout' not in st.session_state:
    st.session_state.layout = 'centered'
st.set_page_config(page_title="æ˜Ÿå°˜å°åŠ©æ‰‹", page_icon=":star:", 
                   layout=st.session_state.layout, 
                   initial_sidebar_state="collapsed", menu_items={
             'Get Help': 'https://stardust.ai',
            #  'Report a bug': "https://www.extremelycoolapp.com/bug",
             'About': "# æ˜Ÿå°˜å°åŠ©æ‰‹. \n *ä»…é™å‘˜å·¥ä½¿ç”¨ï¼Œè¯·å‹¿å¤–ä¼ !*"
    })
st.title("ğŸªæ˜Ÿå°˜å°åŠ©æ‰‹")

# åå­—
with open('names.txt', 'r') as f:
    names = [n.strip() for n in f.readlines()]

if 'name' not in st.session_state:
    st.warning('æœ¬ç³»ç»Ÿéœ€è¦æ¶ˆè€—è®¡ç®—èµ„æºï¼Œç‰¹åˆ«æ˜¯å›¾ç‰‡å’Œè¯­éŸ³åŠŸèƒ½ï¼›è¯·é€‚åº¦ä½“éªŒAIçš„èƒ½åŠ›ï¼Œå°½é‡ç”¨åœ¨å·¥ä½œç›¸å…³å†…å®¹ä¸ŠğŸ˜Š')
    name = st.text_input('è¯·è¾“å…¥ä½ çš„åå­—', key='my_name', help='ä»…é™å‘˜å·¥ä½¿ç”¨ï¼Œè¯·å‹¿å¤–ä¼ ï¼')
    if name:
        st.session_state.name = name
        st.experimental_rerun()
    st.stop()

if st.session_state.name in names:
    st.session_state.guest = False
    

# å®šä¹‰ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºä¿å­˜å¯¹è¯å†…å®¹ã€‚roleï¼šsystemï¼Œuserï¼Œassistant
if "conversation" not in st.session_state:
    st.session_state.conversation = chat.init_prompt.copy()
    if st.session_state.guest:
        st.session_state.conversation.append(
            chat.guest_prompt(st.session_state.name))
    else:
        st.session_state.conversation.append(chat.staff_prompt)

## UI
# å¯¹æ–‡æœ¬è¾“å…¥è¿›è¡Œåº”ç­”
def gen_response():
    task = st.session_state.task
    if task in ['å¯¹è¯', 'ä½œå›¾']:
        user_input = st.session_state.input_text
        if user_input == '':
            return
        st.session_state.input_text = ""
    elif task == 'è¯­éŸ³è¯†åˆ«':
        audio_file = st.session_state.audio
        if audio_file is None:
            return
        user_input = audio_file.name
        
    print(f'{st.session_state.name}({task}): {user_input}')
    st.session_state.conversation.append({"role": "user", "content": user_input})
    # guest è¶…é•¿å¯¹è¯
    if st.session_state.guest and len(st.session_state.conversation) > 10:
        st.session_state.conversation.append({"role": "assistant", "content": 'è®¿å®¢ä¸æ”¯æŒé•¿å¯¹è¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜'})
        return
    # response
    if task == 'å¯¹è¯':
        # with st.spinner('æ­£åœ¨æ€è€ƒ'):
            # response = bot_response["content"]
            # print(f'æ˜Ÿå°˜å°åŠ©æ‰‹: {response}')
            # print('-'*50)
        queue = chat.chat_stream(st.session_state.conversation)
        bot_response = {'role': 'assistant', 'content': '', 'queue': queue, 'active': True}
        response = ''
        st.session_state.conversation.append(bot_response)
    elif task == 'ä½œå›¾':
        with st.spinner('æ­£åœ¨ç»˜åˆ¶'):
            urls = imagegen.gen_image(user_input)
            response = urls
            st.session_state.conversation.append({
                'role': 'imagen',
                'content': urls 
            })
            print(f'Imagen: {response}')
            print('-'*50)
    elif task == 'è¯­éŸ³è¯†åˆ«':
        with st.spinner('æ­£åœ¨è¯†åˆ«'):
            response = asr.transcript(audio_file)
            st.session_state.conversation.append({
                'role': 'audio',
                'content': audio_file
            })
            st.session_state.conversation.append({
                'role': 'assistant',
                'content': response 
            })
            print(f'Whisper: {response}')
            print('-'*50)
    else:
        raise NotImplementedError(task)
    # log
    with open(f'chats/{st.session_state.name}.txt', 'a') as f:
        f.write(f'{st.session_state.name}: {user_input}\n')
        f.write(f'æ˜Ÿå°˜å°åŠ©æ‰‹({task}): {response}\n')
        f.write('-'*50 + '\n')


# æ˜¾ç¤ºå¯¹è¯å†…å®¹
md_formated = ""
for i, c in enumerate(st.session_state.conversation):
    role, content = c['role'], c['content']
    if role == "system":
        continue
    elif role == 'server':# not implemented
        message(content, is_user=False, key=str(i))
    elif role == "user":
        message(content, is_user=True, key=str(i),
                avatar_style='initials', seed=st.session_state.name[-2:])
    elif role == "assistant":
        if c.get('active'):
            queue = c['queue']
            text = ''
            stop = False
            while True:
                content = queue.get()
                if content == chat.finish_token:
                    c.pop('active')
                    c.pop('queue')
                    queue.close()
                    break
                elif not content:
                    break
                else:
                    text += content
            
            c['content'] += text
            message(c['content'], key=str(i), avatar_style='jdenticon')
            time.sleep(0.1)
            st.experimental_rerun()
        else:
            message(c['content'], key=str(i), avatar_style='jdenticon')

    elif role == 'imagen':
        n = len(content)
        cols = st.columns(n)
        for i, col, url in zip(range(1, n+1), cols, content):
            with col:
                st.image(url, use_column_width=True, caption=f'å›¾{i+1}')
    elif role == 'audio':
        c1, c2 = st.columns([0.6,0.4])
        with c2:
            st.audio(content)
    else:
        raise Exception(c)

    # page layout
    if st.session_state.layout != 'wide' and len(c['content']) > WIDE_LAYOUT_THRESHOLD:
        st.session_state.layout = 'wide'
        st.experimental_rerun()

# æ·»åŠ æ–‡æœ¬è¾“å…¥æ¡†
c1, c2 = st.columns([0.15,0.85])
with c1:
    task = st.selectbox('é€‰æ‹©åŠŸèƒ½', ['å¯¹è¯', 'ä½œå›¾', 'è¯­éŸ³è¯†åˆ«'], key='task')
with c2:
    if task in ['å¯¹è¯', 'ä½œå›¾']:
        user_input = st.text_input(label="è¾“å…¥ä½ çš„é—®é¢˜ï¼š", placeholder='è¾“å…¥ä½ çš„é—®é¢˜ï¼Œç„¶åæŒ‰å›è½¦æäº¤ã€‚',
                            help='è¾“å…¥ä½ çš„é—®é¢˜ï¼Œç„¶åæŒ‰å›è½¦æäº¤ã€‚', 
                            max_chars=500,
                            key='input_text',
                            # label_visibility='collapsed',
                            on_change=gen_response)
    elif task == 'è¯­éŸ³è¯†åˆ«':
        audio_file = st.file_uploader('ä¸Šä¼ è¯­éŸ³æ–‡ä»¶', type=asr.accepted_types, key='audio', on_change=gen_response)




## åŠŸèƒ½åŒº
c1, c2, c3 = st.columns([0.1, 0.1, 0.8])
# æ¸…ç©ºå¯¹è¯
with c1:
    if st.button('ğŸ§¹', key='clear'):
        st.session_state.conversation = chat.init_prompt.copy()
        # st.session_state.input_text = ""
        st.session_state.audio = None
        # st.session_state.task = 'å¯¹è¯'
        st.session_state.layout = 'centered'
        st.experimental_rerun()
with c2:
    # å¯¼å‡ºå¯¹è¯å†…å®¹
    def convert_history(conversation):
        history = pd.DataFrame(conversation).query('role not in ["system", "audio"]')
        return history.to_csv().encode('utf-8')
    if st.download_button(label='ğŸ“¤', help='å¯¼å‡ºå¯¹è¯å†…å®¹',
                        data=convert_history(st.session_state.conversation), 
                        file_name=f'history.csv', 
                        mime='text/csv'):
        st.success('å¯¼å‡ºæˆåŠŸï¼')
        
from streamlit_extras.add_vertical_space import add_vertical_space
add_vertical_space(20)
# buy me a coffee
button(username="derekz", floating=False, width=221)
